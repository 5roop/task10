{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = ['Negative', 'Neutral', 'Positive']\n",
    "STR_TO_NUM = {k: i for i, k in enumerate(label_set)}\n",
    "NUM_TO_STR = {i:k for i, k in enumerate(label_set)}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "df = df[[\"sentence\", \"label\", \"split\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "train = df[df.split==\"train\"].drop(columns=[\"split\"])\n",
    "dev = df[df.split==\"dev\"].drop(columns=[\"split\"])\n",
    "test = df[df.split==\"test\"].drop(columns=[\"split\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, model_name):\n",
    "    if model_name == \"EMBEDDIA/crosloengual-bert\":\n",
    "        model_type = \"bert\"\n",
    "        NUM_EPOCH = 3\n",
    "    elif model_name == \"classla/bcms-bertic\":\n",
    "        model_type = \"electra\"\n",
    "        NUM_EPOCH = 9\n",
    "    elif model_name == \"xlm-roberta-base\":\n",
    "        model_type = \"xlmroberta\"\n",
    "        NUM_EPOCH = 40\n",
    "    else:\n",
    "        raise AttributeError(f\"Expected either xlm-roberta-base, classla/bcms-bertic, or EMBEDDIA/crosloengual-bert, got {model_name}.\")\n",
    "\n",
    "    from simpletransformers.classification import ClassificationModel\n",
    "    import torch\n",
    "    torch.cuda.empty_cache()\n",
    "    model_args = {\n",
    "        \"num_train_epochs\": NUM_EPOCH,\n",
    "        \"learning_rate\": 4e-5,\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"train_batch_size\": 8, \n",
    "        \"no_save\": True,\n",
    "        \"no_cache\": True,\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"save_steps\": -1,\n",
    "        \"max_seq_length\": 512,\n",
    "        \"silent\": True,\n",
    "    }\n",
    "\n",
    "    model = ClassificationModel(\n",
    "        model_type, model_name, num_labels=3, use_cuda=True, args=model_args\n",
    "    )\n",
    "    model.train_model(train_df)\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_model(model, test_df):\n",
    "    y_true_enc = test_df.labels\n",
    "    from tqdm.auto import tqdm\n",
    "    y_pred_enc = [model.predict(i)[0][0] for i in tqdm(test_df.text.values)]\n",
    "\n",
    "    y_true = [NUM_TO_STR[i] for i in y_true_enc]\n",
    "    y_pred = [NUM_TO_STR[i] for i in y_pred_enc]\n",
    "    from sklearn.metrics import f1_score\n",
    "    macroF1 = f1_score(y_true, y_pred, labels=label_set, average=\"macro\")\n",
    "\n",
    "    return {\"macroF1\": macroF1, \"y_true\": y_true, \"y_pred\": y_pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabc27234d9c4568a11c98b94e9abd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ae5e2fd0914c07acff8a011dc63eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c28be775c0499bbe0b946294a5f3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876a91874dde479d80841e3c26b0b77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9952a9418a3c46be912f74073fa9f93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf659897fb0e4c16a48ffea1817debd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ecaf73a15c409394008e38123a2a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dad3a3dcca4f459aba692633dc850a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537ca3fb9b09479db53b594de550c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d465d79c13b4c12839ad60d68e3a84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a4ae7fed8f477c8f4c4dcba662b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peterr/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d379e5937e244811874b27f50427ed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f96047456cb4afdbde97acda82db1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = \"xlm-roberta-base classla/bcms-bertic EMBEDDIA/crosloengual-bert\".split()\n",
    "# models = [\"EMBEDDIA/crosloengual-bert\"]\n",
    "models = [\"classla/bcms-bertic\"]\n",
    "from tqdm.auto import tqdm\n",
    "for model_name in tqdm(models*6):\n",
    "    # Full train-test:\n",
    "    model = train_model(train, model_name)\n",
    "    # df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "    # df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "    # df = df[[\"sentence\", \"label\", \"split\", \"country\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "    # train = df[df.split==\"train\"].drop(columns=[\"split\", \"country\"])\n",
    "    # condition_is_test = df.split==\"test\"\n",
    "    # test = df[condition_is_test].drop(columns=[\"split\", \"country\"])\n",
    "    # stats = eval_model(model, test)\n",
    "    # stats[\"train_split\"] = \"train\"\n",
    "    # stats[\"eval_split\"] = \"test\"\n",
    "    # stats[\"model_name\"] = model_name\n",
    "    # with open(\"007_results.jsonl\", \"a\") as f:\n",
    "    #     f.write(f\"{stats}\\n\")\n",
    "\n",
    "    # condition_is_dev = df.split==\"dev\"\n",
    "    # dev = df[condition_is_dev].drop(columns=[\"split\", \"country\"])\n",
    "    # stats = eval_model(model, dev)\n",
    "    # stats[\"train_split\"] = \"train\"\n",
    "    # stats[\"eval_split\"] = \"dev\"\n",
    "    # stats[\"model_name\"] = model_name\n",
    "    # with open(\"007_results.jsonl\", \"a\") as f:\n",
    "    #     f.write(f\"{stats}\\n\")\n",
    "        \n",
    "    # Eval on specific countries\n",
    "    for country in [\n",
    "    #     \"HR\", \n",
    "    # \"SRB\", \n",
    "    \"BiH\"\n",
    "    ]:\n",
    "        import pandas as pd\n",
    "        df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "        df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "        df = df[[\"sentence\", \"label\", \"split\", \"country\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "        condition_is_test = df.split==\"test\"\n",
    "        condition_is_lang = df.country == country\n",
    "        test = df[condition_is_test & condition_is_lang].drop(columns=[\"split\", \"country\"])\n",
    "        stats = eval_model(model, test)\n",
    "        stats[\"train_split\"] = \"train\"\n",
    "        stats[\"eval_split\"] = f\"test_{country}\"\n",
    "        stats[\"model_name\"] = model_name\n",
    "        with open(\"007_results.jsonl\", \"a\") as f:\n",
    "            f.write(f\"{stats}\\n\")\n",
    "\n",
    "        condition_is_dev = df.split==\"dev\"\n",
    "        condition_is_lang = df.country == country\n",
    "        dev = df[condition_is_dev & condition_is_lang].drop(columns=[\"split\", \"country\"])\n",
    "        stats = eval_model(model, dev)\n",
    "        stats[\"train_split\"] = \"train\"\n",
    "        stats[\"eval_split\"] = f\"dev_{country}\"\n",
    "        stats[\"model_name\"] = model_name\n",
    "        with open(\"007_results.jsonl\", \"a\") as f:\n",
    "            f.write(f\"{stats}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = \"xlm-roberta-base classla/bcms-bertic EMBEDDIA/crosloengual-bert\".split()\n",
    "# from tqdm.auto import tqdm\n",
    "# for model_name in tqdm(models*5):\n",
    "#     model = train_model(train, model_name)\n",
    "#     stats = eval_model(model, test)\n",
    "#     stats[\"train_split\"] = \"train\"\n",
    "#     stats[\"eval_split\"] = \"test\"\n",
    "#     stats[\"model_name\"] = model_name\n",
    "#     with open(\"007_results.jsonl\", \"a\") as f:\n",
    "#         f.write(f\"{stats}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on train, evaluate on specific country\n",
    "\n",
    "This was done already in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = \"xlm-roberta-base classla/bcms-bertic EMBEDDIA/crosloengual-bert\".split()\n",
    "# from tqdm.auto import tqdm\n",
    "# for model_name in tqdm(models*6):\n",
    "#     model = train_model(train, model_name)\n",
    "#     for country in [\"HR\", \"SRB\"]:\n",
    "#         import pandas as pd\n",
    "#         df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "#         df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "#         df = df[[\"sentence\", \"label\", \"split\", \"country\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "#         condition_is_test = df.split==\"test\"\n",
    "#         condition_is_lang = df.country == country\n",
    "#         test = df[condition_is_test & condition_is_lang].drop(columns=[\"split\", \"country\"])\n",
    "#         stats = eval_model(model, test)\n",
    "#         stats[\"train_split\"] = \"train\"\n",
    "#         stats[\"eval_split\"] = f\"test_{country}\"\n",
    "#         stats[\"model_name\"] = model_name\n",
    "#         with open(\"007_results.jsonl\", \"a\") as f:\n",
    "#             f.write(f\"{stats}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on specific country, evaluate on specific country:\n",
    "\n",
    "The implementation is less than elegant (by light years), but this was written when the training was already underway and reformatting would require restarting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = \"xlm-roberta-base classla/bcms-bertic EMBEDDIA/crosloengual-bert\".split()\n",
    "# models = [\"EMBEDDIA/crosloengual-bert\"]\n",
    "from tqdm.auto import tqdm\n",
    "for model_name in tqdm(models*6):\n",
    "    for country_train in [\"HR\", \"SRB\"]:\n",
    "        df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "        df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "        df = df[[\"sentence\", \"label\", \"split\", \"country\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "        condition_is_train = df.split==\"train\"\n",
    "        condition_is_lang = df.country == country_train\n",
    "        train = df[condition_is_train & condition_is_lang].drop(columns=[\"split\", \"country\"])\n",
    "        model = train_model(train, model_name)\n",
    "        for country_eval in [\"HR\", \"SRB\"]:\n",
    "            df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "            df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "            df = df[[\"sentence\", \"label\", \"split\", \"country\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "            condition_is_test = df.split==\"test\"\n",
    "            condition_is_lang = df.country == country_eval\n",
    "            test = df[condition_is_test & condition_is_lang].drop(columns=[\"split\", \"country\"])\n",
    "            stats = eval_model(model, test)\n",
    "            stats[\"train_split\"] = f\"train_{country_train}\"\n",
    "            stats[\"eval_split\"] = f\"test_{country_eval}\"\n",
    "            stats[\"model_name\"] = model_name\n",
    "            with open(\"007_results.jsonl\", \"a\") as f:\n",
    "                f.write(f\"{stats}\\n\")\n",
    "\n",
    "            df = pd.read_json(\"bcs_polsent_007.jsonl\", orient=\"records\", lines=True)\n",
    "            df[\"label\"] = df.label.apply(lambda s: STR_TO_NUM[s])\n",
    "            df = df[[\"sentence\", \"label\", \"split\", \"country\"]].rename(columns={\"sentence\": \"text\", \"label\":\"labels\"})\n",
    "            condition_is_dev = df.split==\"dev\"\n",
    "            condition_is_lang = df.country == country_eval\n",
    "            dev = df[condition_is_dev & condition_is_lang].drop(columns=[\"split\", \"country\"])\n",
    "            stats = eval_model(model, dev)\n",
    "            stats[\"train_split\"] = f\"train_{country_train}\"\n",
    "            stats[\"eval_split\"] = f\"dev_{country_eval}\"\n",
    "            stats[\"model_name\"] = model_name\n",
    "            with open(\"007_results.jsonl\", \"a\") as f:\n",
    "                f.write(f\"{stats}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d30c88cb7145d662123f76f8c64609bc18e52940d2861adec2407b68f2e334f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
